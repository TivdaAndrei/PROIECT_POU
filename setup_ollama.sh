#!/bin/bash
# Setup Ollama for natural conversations with Pou

echo "ðŸ¤– Setting up Ollama for Natural Conversations"
echo ""

# Check if ollama is installed
if ! command -v ollama &> /dev/null; then
    echo "ðŸ“¥ Installing Ollama..."
    curl -fsSL https://ollama.com/install.sh | sh
    echo ""
fi

echo "âœ… Ollama installed!"
echo ""

# Start Ollama service
echo "ðŸš€ Starting Ollama service..."
ollama serve &
OLLAMA_PID=$!
sleep 3

echo ""
echo "ðŸ“¦ Pulling Llama 3.2 model (small, fast, ~2GB)..."
echo "   This will take a few minutes on first run..."
ollama pull llama3.2:latest

echo ""
echo "âœ… Setup complete!"
echo ""
echo "ðŸ“‹ Ollama is now running with model: llama3.2:latest"
echo ""
echo "ðŸ’¡ Tips:"
echo "   - Ollama runs in background automatically"
echo "   - Uses about 2-4GB RAM"
echo "   - Responses are generated locally (private)"
echo "   - To use a different model: ollama pull mistral"
echo ""
echo "ðŸŽ¤ Now Pou can have natural conversations with you!"
echo "   Say 'Hi friend' and ask anything!"
echo ""
echo "To stop Ollama: pkill ollama"
